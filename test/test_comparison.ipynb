{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with the R version of `tximport`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is included to provide the code used to generate the output from `tximport` that the test in `test_correctness.py` compares against. It will note be automatically run by `pytest` and the assertions provided at the end are redundant, since they are already included in `test_correctness.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"R version 4.3.1 (2023-06-16)\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "R.version.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 244191 Columns: 2\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (2): transcript_id, gene_id\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31498\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "summarizing inferential replicates\n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "summarizing inferential replicates\n",
       "1 2 3 4 \n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(tximport)\n",
    "library(readr)\n",
    "dir <- \"./data/fabry_disease\"\n",
    "tx2gene <- read_tsv(file.path(dir, \"transcript_gene_mapping_human.csv\"))\n",
    "rowMedians <- function(x) {\n",
    "    apply(x, 1, median, na.rm = TRUE)\n",
    "}\n",
    "files <- c(\n",
    "    file.path(dir, \"SRR16504309_wt/quant.sf\"),\n",
    "    file.path(dir, \"SRR16504310_wt/quant.sf\"),\n",
    "    file.path(dir, \"SRR16504311_ko/quant.sf\"),\n",
    "    file.path(dir, \"SRR16504312_ko/quant.sf\")\n",
    ")\n",
    "countsFromAbundanceOptions <- c(\"no\", \"scaledTPM\", \"lengthScaledTPM\")\n",
    "for (idx in seq_along(countsFromAbundanceOptions)) {\n",
    "    txi <- tximport(\n",
    "        files,\n",
    "        type = \"salmon\",\n",
    "        tx2gene = tx2gene,\n",
    "        countsFromAbundance = countsFromAbundanceOptions[idx],\n",
    "        dropInfReps = TRUE,\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport.csv\")\n",
    "    if (!is.null(countsFromAbundanceOptions[idx])) {\n",
    "        writePath <- gsub(\".csv\", paste0(\"_\", countsFromAbundanceOptions[idx], \".csv\"), writePath)\n",
    "    }\n",
    "    write.csv(txi$counts, writePath)\n",
    "}\n",
    "dataTypeOptions <- c(\"kallisto\", \"salmon\")\n",
    "for (idx in seq_along(dataTypeOptions)) {\n",
    "\n",
    "    if (dataTypeOptions[idx] == \"kallisto\") {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504310_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504311_ko/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504312_ko/abundance.h5\")\n",
    "        )\n",
    "    } else {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504310_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504311_ko/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504312_ko/quant.sf\")\n",
    "        )\n",
    "    }\n",
    "\n",
    "    txi <- tximport(\n",
    "        files,\n",
    "        type = dataTypeOptions[idx],\n",
    "        tx2gene = tx2gene,\n",
    "        countsFromAbundance = \"no\",\n",
    "        dropInfReps = FALSE,\n",
    "        infRepStat = rowMedians,\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport_bootstrap.csv\")\n",
    "    writePath <- gsub(\".csv\", paste0(\"_\", dataTypeOptions[idx], \".csv\"), writePath)\n",
    "    write.csv(txi$counts, writePath)\n",
    "}\n",
    "for (idx in seq_along(dataTypeOptions)) {\n",
    "\n",
    "    if (dataTypeOptions[idx] == \"kallisto\") {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504310_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504311_ko/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504312_ko/abundance.h5\")\n",
    "        )\n",
    "    } else {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504310_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504311_ko/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504312_ko/quant.sf\")\n",
    "        )\n",
    "    }\n",
    "\n",
    "    txi <- tximport(\n",
    "        files,\n",
    "        type = dataTypeOptions[idx],\n",
    "        tx2gene = tx2gene,\n",
    "        countsFromAbundance = \"no\",\n",
    "        txOut = TRUE,\n",
    "        dropInfReps = FALSE,\n",
    "        infRepStat = rowMedians,\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport_bootstrap_transcripts.csv\")\n",
    "    writePath <- gsub(\".csv\", paste0(\"_\", dataTypeOptions[idx], \".csv\"), writePath)\n",
    "    write.csv(txi$counts, writePath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 17:08:34,425: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.45it/s]\n",
      "2024-06-11 17:08:35,700: Converting transcript-level expression to gene-level expression.\n",
      "2024-06-11 17:08:36,111: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-06-11 17:08:36,392: Matching gene_ids.\n",
      "2024-06-11 17:08:36,550: Creating gene abundance.\n",
      "2024-06-11 17:08:36,964: Creating gene counts.\n",
      "2024-06-11 17:08:37,043: Creating lengths.\n",
      "2024-06-11 17:08:37,164: Replacing missing lengths.\n",
      "2024-06-11 17:08:42,420: Creating gene expression dataset.\n",
      "2024-06-11 17:08:42,450: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_no.csv.\n",
      "2024-06-11 17:08:42,521: Finished the import in 8.10 seconds.\n",
      "2024-06-11 17:08:44,060: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.54it/s]\n",
      "2024-06-11 17:08:45,298: Converting transcript-level expression to gene-level expression.\n",
      "2024-06-11 17:08:45,688: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-06-11 17:08:45,964: Matching gene_ids.\n",
      "2024-06-11 17:08:46,133: Creating gene abundance.\n",
      "2024-06-11 17:08:46,367: Creating gene counts.\n",
      "2024-06-11 17:08:46,437: Creating lengths.\n",
      "2024-06-11 17:08:46,541: Replacing missing lengths.\n",
      "2024-06-11 17:08:51,343: Recreating gene counts from abundances.\n",
      "2024-06-11 17:08:51,343: Setting the counts to scaled TPM.\n",
      "2024-06-11 17:08:51,344: Creating gene expression dataset.\n",
      "2024-06-11 17:08:51,373: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_scaledTPM.csv.\n",
      "2024-06-11 17:08:51,465: Finished the import in 7.41 seconds.\n",
      "2024-06-11 17:08:52,957: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.45it/s]\n",
      "2024-06-11 17:08:54,233: Converting transcript-level expression to gene-level expression.\n",
      "2024-06-11 17:08:54,656: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-06-11 17:08:54,959: Matching gene_ids.\n",
      "2024-06-11 17:08:55,125: Creating gene abundance.\n",
      "2024-06-11 17:08:55,371: Creating gene counts.\n",
      "2024-06-11 17:08:55,449: Creating lengths.\n",
      "2024-06-11 17:08:55,567: Replacing missing lengths.\n",
      "2024-06-11 17:09:00,923: Recreating gene counts from abundances.\n",
      "2024-06-11 17:09:00,923: Setting counts to length scaled TPM.\n",
      "2024-06-11 17:09:00,926: Creating gene expression dataset.\n",
      "2024-06-11 17:09:00,954: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_lengthScaledTPM.csv.\n",
      "2024-06-11 17:09:01,045: Finished the import in 8.09 seconds.\n"
     ]
    }
   ],
   "source": [
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_no.csv\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_scaledTPM.csv -c scaled_tpm\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv -c length_scaled_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts_tximport_no = pd.read_csv(\"./data/fabry_disease/counts_tximport_no.csv\")\n",
    "counts_tximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_scaledTPM.csv\")\n",
    "counts_tximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_lengthScaledTPM.csv\")\n",
    "\n",
    "counts_pytximport_no = pd.read_csv(\"./data/fabry_disease/counts_pytximport_no.csv\")\n",
    "counts_pytximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_scaledTPM.csv\")\n",
    "counts_pytximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv\")\n",
    "counts_pytximport_no.columns = counts_tximport_no.columns\n",
    "counts_pytximport_scaledTPM.columns = counts_tximport_scaledTPM.columns\n",
    "counts_pytximport_lengthScaledTPM.columns = counts_tximport_lengthScaledTPM.columns\n",
    "\n",
    "pd.testing.assert_frame_equal(counts_tximport_no, counts_pytximport_no)\n",
    "pd.testing.assert_frame_equal(counts_tximport_scaledTPM, counts_pytximport_scaledTPM)\n",
    "pd.testing.assert_frame_equal(counts_tximport_lengthScaledTPM, counts_pytximport_lengthScaledTPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare outputs for transcript-level summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 244191 Columns: 2\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (2): transcript_id, gene_id\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reading in files with read_tsv\n",
       "1 \n",
       "reading in files with read_tsv\n",
       "1 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "dir <- \"./data/salmon\"\n",
    "files_protein_coding <- c(\n",
    "  file.path(dir, \"quant.sf\")\n",
    ")\n",
    "tx2gene <- read_tsv(file.path(\"./data/fabry_disease\", \"transcript_gene_mapping_human.csv\"))\n",
    "countsFromAbundanceOptions <- c(\"scaledTPM\", \"dtuScaledTPM\")\n",
    "for (idx in seq_along(countsFromAbundanceOptions)) {\n",
    "    txi <- tximport(\n",
    "        files_protein_coding,\n",
    "        type = \"salmon\",\n",
    "        tx2gene = tx2gene,\n",
    "        txOut = TRUE,\n",
    "        countsFromAbundance = countsFromAbundanceOptions[idx],\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport.csv\")\n",
    "    if (!is.null(countsFromAbundanceOptions[idx])) {\n",
    "        writePath <- gsub(\".csv\", paste0(\"_\", countsFromAbundanceOptions[idx], \".csv\"), writePath)\n",
    "    }\n",
    "    write.csv(txi$counts, writePath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-11 17:09:03,452: Starting the import.\n",
      "Reading quantification files: 1it [00:00, 295.94it/s]\n",
      "2024-06-11 17:09:03,827: Setting counts to length scaled TPM.\n",
      "2024-06-11 17:09:03,828: Saving the gene-level expression to: data/salmon/counts_pytximport_dtuScaledTPM.csv.\n",
      "2024-06-11 17:09:03,830: Finished the import in 0.38 seconds.\n"
     ]
    }
   ],
   "source": [
    "!pytximport -i ./data/salmon/quant.sf -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/salmon/counts_pytximport_dtuScaledTPM.csv -t salmon -tx -c dtu_scaled_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_tximport_dtuScaledTPM = pd.read_csv(\"./data/salmon/counts_tximport_dtuScaledTPM.csv\", index_col=0).sort_index()\n",
    "counts_pytximport_dtuScaledTPM = pd.read_csv(\n",
    "    \"./data/salmon/counts_pytximport_dtuScaledTPM.csv\", index_col=0\n",
    ").sort_index()\n",
    "# cut the transcript version from the index\n",
    "counts_tximport_dtuScaledTPM.index = counts_tximport_dtuScaledTPM.index.str.split(\".\").str[0]\n",
    "counts_pytximport_dtuScaledTPM.columns = counts_tximport_dtuScaledTPM.columns\n",
    "\n",
    "pd.testing.assert_frame_equal(counts_tximport_dtuScaledTPM, counts_pytximport_dtuScaledTPM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
