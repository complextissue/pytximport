{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with the R version of `tximport`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is included to provide the code used to generate the output from `tximport` that the test in `test_correctness.py` compares against. It will note be automatically run by `pytest` and the assertions provided at the end are redundant, since they are already included in `test_correctness.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"R version 4.3.1 (2023-06-16)\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "R.version.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 244191 Columns: 2\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (2): transcript_id, gene_id\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "[1] 1\n",
      "[1] 2\n",
      "[1] 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(tximport)\n",
    "library(readr)\n",
    "dir <- \"./data/fabry_disease\"\n",
    "tx2gene <- read_tsv(file.path(dir, \"transcript_gene_mapping_human.csv\"))\n",
    "files <- c(\n",
    "  file.path(dir, \"SRR16504309_wt.sf\"),\n",
    "  file.path(dir, \"SRR16504310_wt.sf\"),\n",
    "  file.path(dir, \"SRR16504311_ko.sf\"),\n",
    "  file.path(dir, \"SRR16504312_ko.sf\")\n",
    ")\n",
    "countsFromAbundanceOptions <- c(\"no\", \"scaledTPM\", \"lengthScaledTPM\")\n",
    "for (idx in seq_along(countsFromAbundanceOptions)) {\n",
    "  txi <- tximport(\n",
    "    files,\n",
    "    type = \"salmon\",\n",
    "    tx2gene = tx2gene,\n",
    "    countsFromAbundance = countsFromAbundanceOptions[idx],\n",
    "    ignoreTxVersion = TRUE,\n",
    "    ignoreAfterBar = TRUE\n",
    "  )\n",
    "  print(idx)\n",
    "  writePath <- file.path(dir, \"counts_tximport.csv\")\n",
    "  if (!is.null(countsFromAbundanceOptions[idx])) {\n",
    "    writePath <- gsub(\".csv\", paste0(\"_\", countsFromAbundanceOptions[idx], \".csv\"), writePath)\n",
    "  }\n",
    "  write.csv(txi$counts, writePath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-30 21:04:42,063: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.58it/s]\n",
      "2024-05-30 21:04:43,294: Converting transcript-level expression to gene-level expression.\n",
      "2024-05-30 21:04:43,671: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-05-30 21:04:43,952: Matching gene_ids.\n",
      "2024-05-30 21:04:44,116: Creating gene abundance.\n",
      "2024-05-30 21:04:44,213: Creating gene counts.\n",
      "2024-05-30 21:04:44,342: Creating lengths.\n",
      "2024-05-30 21:04:44,495: Replacing missing lengths.\n",
      "2024-05-30 21:04:50,105: Creating gene expression dataset.\n",
      "2024-05-30 21:04:50,136: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_no.csv.\n",
      "2024-05-30 21:04:50,207: Finished the import in 8.14 seconds.\n",
      "2024-05-30 21:04:51,406: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.63it/s]\n",
      "2024-05-30 21:04:52,631: Converting transcript-level expression to gene-level expression.\n",
      "2024-05-30 21:04:53,053: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-05-30 21:04:53,313: Matching gene_ids.\n",
      "2024-05-30 21:04:53,467: Creating gene abundance.\n",
      "2024-05-30 21:04:53,561: Creating gene counts.\n",
      "2024-05-30 21:04:53,663: Creating lengths.\n",
      "2024-05-30 21:04:53,755: Replacing missing lengths.\n",
      "2024-05-30 21:04:59,260: Recreating gene counts from abundances.\n",
      "2024-05-30 21:04:59,260: Setting the counts to scaled TPM.\n",
      "2024-05-30 21:04:59,261: Creating gene expression dataset.\n",
      "2024-05-30 21:04:59,290: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_scaledTPM.csv.\n",
      "2024-05-30 21:04:59,449: Finished the import in 8.04 seconds.\n",
      "2024-05-30 21:05:00,696: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.45it/s]\n",
      "2024-05-30 21:05:01,977: Converting transcript-level expression to gene-level expression.\n",
      "2024-05-30 21:05:02,376: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-05-30 21:05:02,656: Matching gene_ids.\n",
      "2024-05-30 21:05:02,816: Creating gene abundance.\n",
      "2024-05-30 21:05:02,910: Creating gene counts.\n",
      "2024-05-30 21:05:03,002: Creating lengths.\n",
      "2024-05-30 21:05:03,096: Replacing missing lengths.\n",
      "2024-05-30 21:05:08,628: Recreating gene counts from abundances.\n",
      "2024-05-30 21:05:08,628: Setting counts to length scaled TPM.\n",
      "2024-05-30 21:05:08,631: Creating gene expression dataset.\n",
      "2024-05-30 21:05:08,658: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_lengthScaledTPM.csv.\n",
      "2024-05-30 21:05:08,751: Finished the import in 8.06 seconds.\n"
     ]
    }
   ],
   "source": [
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_no.csv\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_scaledTPM.csv -c scaled_tpm\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv -c length_scaled_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts_tximport_no = pd.read_csv(\"./data/fabry_disease/counts_tximport_no.csv\")\n",
    "counts_tximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_scaledTPM.csv\")\n",
    "counts_tximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_lengthScaledTPM.csv\")\n",
    "\n",
    "counts_pytximport_no = pd.read_csv(\"./data/fabry_disease/counts_pytximport_no.csv\")\n",
    "counts_pytximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_scaledTPM.csv\")\n",
    "counts_pytximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv\")\n",
    "counts_pytximport_no.columns = counts_tximport_no.columns\n",
    "counts_pytximport_scaledTPM.columns = counts_tximport_scaledTPM.columns\n",
    "counts_pytximport_lengthScaledTPM.columns = counts_tximport_lengthScaledTPM.columns\n",
    "\n",
    "pd.testing.assert_frame_equal(counts_tximport_no, counts_pytximport_no)\n",
    "pd.testing.assert_frame_equal(counts_tximport_scaledTPM, counts_pytximport_scaledTPM)\n",
    "pd.testing.assert_frame_equal(counts_tximport_lengthScaledTPM, counts_pytximport_lengthScaledTPM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
