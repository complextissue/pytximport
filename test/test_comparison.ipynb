{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with the R version of `tximport`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is included to provide the code used to generate the output from `tximport` that the test in `test_correctness.py` compares against. It will note be automatically run by `pytest` and the assertions provided at the end are redundant, since they are already included in `test_correctness.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"R version 4.3.1 (2023-06-16)\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "R.version.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 244191 Columns: 2\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (2): transcript_id, gene_id\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n",
      "[1] 1\n",
      "[1] 2\n",
      "[1] 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n",
       "reading in files with read_tsv\n",
       "1 2 3 4 \n",
       "transcripts missing from tx2gene: 31380\n",
       "summarizing abundance\n",
       "summarizing counts\n",
       "summarizing length\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "library(tximport)\n",
    "library(readr)\n",
    "dir <- \"./data/fabry_disease\"\n",
    "tx2gene <- read_tsv(file.path(dir, \"transcript_gene_mapping_human.csv\"))\n",
    "files <- c(\n",
    "  file.path(dir, \"SRR16504309_wt.sf\"),\n",
    "  file.path(dir, \"SRR16504310_wt.sf\"),\n",
    "  file.path(dir, \"SRR16504311_ko.sf\"),\n",
    "  file.path(dir, \"SRR16504312_ko.sf\")\n",
    ")\n",
    "countsFromAbundanceOptions <- c(\"no\", \"scaledTPM\", \"lengthScaledTPM\")\n",
    "for (idx in seq_along(countsFromAbundanceOptions)) {\n",
    "  txi <- tximport(\n",
    "    files,\n",
    "    type = \"salmon\",\n",
    "    tx2gene = tx2gene,\n",
    "    countsFromAbundance = countsFromAbundanceOptions[idx],\n",
    "    ignoreTxVersion = TRUE,\n",
    "    ignoreAfterBar = TRUE\n",
    "  )\n",
    "  print(idx)\n",
    "  writePath <- file.path(dir, \"counts_tximport.csv\")\n",
    "  if (!is.null(countsFromAbundanceOptions[idx])) {\n",
    "    writePath <- gsub(\".csv\", paste0(\"_\", countsFromAbundanceOptions[idx], \".csv\"), writePath)\n",
    "  }\n",
    "  write.csv(txi$counts, writePath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-04 19:00:50,027: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  2.84it/s]\n",
      "2024-06-04 19:00:51,561: Converting transcript-level expression to gene-level expression.\n",
      "2024-06-04 19:00:51,981: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-06-04 19:00:52,335: Matching gene_ids.\n",
      "2024-06-04 19:00:52,542: Creating gene abundance.\n",
      "2024-06-04 19:00:52,820: Creating gene counts.\n",
      "2024-06-04 19:00:52,936: Creating lengths.\n",
      "2024-06-04 19:00:53,089: Replacing missing lengths.\n",
      "2024-06-04 19:00:58,156: Creating gene expression dataset.\n",
      "2024-06-04 19:00:58,193: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_no.csv.\n",
      "2024-06-04 19:00:58,273: Finished the import in 8.25 seconds.\n",
      "2024-06-04 19:00:59,769: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  2.66it/s]\n",
      "2024-06-04 19:01:01,409: Converting transcript-level expression to gene-level expression.\n",
      "2024-06-04 19:01:01,837: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-06-04 19:01:02,160: Matching gene_ids.\n",
      "2024-06-04 19:01:02,321: Creating gene abundance.\n",
      "2024-06-04 19:01:02,599: Creating gene counts.\n",
      "2024-06-04 19:01:02,673: Creating lengths.\n",
      "2024-06-04 19:01:02,791: Replacing missing lengths.\n",
      "2024-06-04 19:01:07,705: Recreating gene counts from abundances.\n",
      "2024-06-04 19:01:07,706: Setting the counts to scaled TPM.\n",
      "2024-06-04 19:01:07,707: Creating gene expression dataset.\n",
      "2024-06-04 19:01:07,736: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_scaledTPM.csv.\n",
      "2024-06-04 19:01:07,827: Finished the import in 8.06 seconds.\n",
      "2024-06-04 19:01:09,437: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.27it/s]\n",
      "2024-06-04 19:01:10,794: Converting transcript-level expression to gene-level expression.\n",
      "2024-06-04 19:01:11,424: Not all transcripts are present in the mapping. 31380 out of 253181 missing.\n",
      "2024-06-04 19:01:11,870: Matching gene_ids.\n",
      "2024-06-04 19:01:12,045: Creating gene abundance.\n",
      "2024-06-04 19:01:12,385: Creating gene counts.\n",
      "2024-06-04 19:01:12,462: Creating lengths.\n",
      "2024-06-04 19:01:12,586: Replacing missing lengths.\n",
      "2024-06-04 19:01:17,438: Recreating gene counts from abundances.\n",
      "2024-06-04 19:01:17,439: Setting counts to length scaled TPM.\n",
      "2024-06-04 19:01:17,444: Creating gene expression dataset.\n",
      "2024-06-04 19:01:17,484: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_lengthScaledTPM.csv.\n",
      "2024-06-04 19:01:17,586: Finished the import in 8.15 seconds.\n"
     ]
    }
   ],
   "source": [
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_no.csv\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_scaledTPM.csv -c scaled_tpm\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt.sf -i ./data/fabry_disease/SRR16504310_wt.sf -i ./data/fabry_disease/SRR16504311_ko.sf -i ./data/fabry_disease/SRR16504312_ko.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.csv -o ./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv -c length_scaled_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts_tximport_no = pd.read_csv(\"./data/fabry_disease/counts_tximport_no.csv\")\n",
    "counts_tximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_scaledTPM.csv\")\n",
    "counts_tximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_lengthScaledTPM.csv\")\n",
    "\n",
    "counts_pytximport_no = pd.read_csv(\"./data/fabry_disease/counts_pytximport_no.csv\")\n",
    "counts_pytximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_scaledTPM.csv\")\n",
    "counts_pytximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv\")\n",
    "counts_pytximport_no.columns = counts_tximport_no.columns\n",
    "counts_pytximport_scaledTPM.columns = counts_tximport_scaledTPM.columns\n",
    "counts_pytximport_lengthScaledTPM.columns = counts_tximport_lengthScaledTPM.columns\n",
    "\n",
    "pd.testing.assert_frame_equal(counts_tximport_no, counts_pytximport_no)\n",
    "pd.testing.assert_frame_equal(counts_tximport_scaledTPM, counts_pytximport_scaledTPM)\n",
    "pd.testing.assert_frame_equal(counts_tximport_lengthScaledTPM, counts_pytximport_lengthScaledTPM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
