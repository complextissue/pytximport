{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with the R version of `tximport`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is included to provide the code used to generate the output from `tximport` that the test in `test_correctness.py` compares against. It will note be automatically run by `pytest` and the assertions provided at the end are redundant, since they are already included in `test_correctness.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rpy2==3.4.5 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mrpy2 version:\u001b[0m\n",
      "3.4.5\n",
      "\u001b[1mPython version:\u001b[0m\n",
      "3.9.16 (main, Sep 11 2024, 11:23:52) \n",
      "[Clang 15.0.0 (clang-1500.3.9.4)]\n",
      "\u001b[1mLooking for R's HOME:\u001b[0m\n",
      "    Environment variable R_HOME: None\n",
      "    Calling `R RHOME`: /Library/Frameworks/R.framework/Resources\n",
      "    Environment variable R_LIBS_USER: None\n",
      "\u001b[1mR's additions to LD_LIBRARY_PATH:\u001b[0m\n",
      "\n",
      "\u001b[1mR version:\u001b[0m\n",
      "    In the PATH: R version 4.3.1 (2023-06-16) -- \"Beagle Scouts\"\n",
      "    Loading R library from rpy2: OK\n",
      "\u001b[1mAdditional directories to load R packages from:\u001b[0m\n",
      "None\n",
      "\u001b[1mC extension compilation:\u001b[0m\n",
      "  include:\n",
      "  ['/Library/Frameworks/R.framework/Resources/include']\n",
      "  libraries:\n",
      "  ['pcre2-8', 'lzma', 'bz2', 'z', 'icucore', 'dl', 'm', 'iconv']\n",
      "  library_dirs:\n",
      "  ['/opt/R/arm64/lib', '/opt/R/arm64/lib']\n",
      "  extra_compile_args:\n",
      "  []\n",
      "  extra_link_args:\n",
      "  ['-F/Library/Frameworks/R.framework/..', '-framework', 'R']\n"
     ]
    }
   ],
   "source": [
    "!python3 -m rpy2.situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"R version 4.3.1 (2023-06-16)\"\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "R.version.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bitte einen CRAN-Spiegelserver für diese Sitzung auswählen ---\n",
      "Secure CRAN mirrors \n",
      "\n",
      " 1: 0-Cloud [https]\n",
      " 2: Australia (Canberra) [https]\n",
      " 3: Australia (Melbourne 1) [https]\n",
      " 4: Australia (Melbourne 2) [https]\n",
      " 5: Austria [https]\n",
      " 6: Belgium (Brussels) [https]\n",
      " 7: Brazil (PR) [https]\n",
      " 8: Brazil (SP 1) [https]\n",
      " 9: Brazil (SP 2) [https]\n",
      "10: Bulgaria [https]\n",
      "11: Canada (MB) [https]\n",
      "12: Canada (ON 1) [https]\n",
      "13: Canada (ON 2) [https]\n",
      "14: Chile (Santiago) [https]\n",
      "15: China (Beijing 2) [https]\n",
      "16: China (Beijing 3) [https]\n",
      "17: China (Hefei) [https]\n",
      "18: China (Hong Kong) [https]\n",
      "19: China (Guangzhou) [https]\n",
      "20: China (Jinan) [https]\n",
      "21: China (Nanjing) [https]\n",
      "22: China (Shanghai 2) [https]\n",
      "23: China (Shenzhen) [https]\n",
      "24: China (Wuhan) [https]\n",
      "25: Colombia (Cali) [https]\n",
      "26: Costa Rica [https]\n",
      "27: Cyprus [https]\n",
      "28: Czech Republic [https]\n",
      "29: Denmark [https]\n",
      "30: East Asia [https]\n",
      "31: Ecuador (Cuenca) [https]\n",
      "32: France (Lyon 1) [https]\n",
      "33: France (Lyon 2) [https]\n",
      "34: France (Marseille) [https]\n",
      "35: France (Paris 1) [https]\n",
      "36: Germany (Erlangen) [https]\n",
      "37: Germany (Göttingen) [https]\n",
      "38: Germany (Leipzig) [https]\n",
      "39: Germany (Münster) [https]\n",
      "40: Greece [https]\n",
      "41: Iceland [https]\n",
      "42: India (Bengaluru) [https]\n",
      "43: India (Bhubaneswar) [https]\n",
      "44: Indonesia (Banda Aceh) [https]\n",
      "45: Iran (Mashhad) [https]\n",
      "46: Italy (Milano) [https]\n",
      "47: Italy (Padua) [https]\n",
      "48: Japan (Yonezawa) [https]\n",
      "49: Korea (Gyeongsan-si) [https]\n",
      "50: Mexico (Mexico City) [https]\n",
      "51: Mexico (Texcoco) [https]\n",
      "52: Morocco [https]\n",
      "53: Netherlands (Dronten) [https]\n",
      "54: New Zealand [https]\n",
      "55: Norway [https]\n",
      "56: South Africa (Johannesburg) [https]\n",
      "57: Spain (A Coruña) [https]\n",
      "58: Spain (Madrid) [https]\n",
      "59: Sweden (Umeå) [https]\n",
      "60: Switzerland (Zurich 1) [https]\n",
      "61: Taiwan (Taipei) [https]\n",
      "62: Turkey (Denizli) [https]\n",
      "63: Turkey (Istanbul) [https]\n",
      "64: UK (Bristol) [https]\n",
      "65: UK (London 1) [https]\n",
      "66: USA (IA) [https]\n",
      "67: USA (MI) [https]\n",
      "68: USA (MO) [https]\n",
      "69: USA (OH) [https]\n",
      "70: USA (OR) [https]\n",
      "71: USA (PA 1) [https]\n",
      "72: USA (TN) [https]\n",
      "73: United Arab Emirates [https]\n",
      "74: Uruguay [https]\n",
      "75: (other mirrors)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: versuche URL 'https://ftp.gwdg.de/pub/misc/cran/bin/macosx/big-sur-arm64/contrib/4.3/matrixStats_1.4.1.tgz'\n",
      "\n",
      "R[write to console]: Content type 'application/octet-stream'\n",
      "R[write to console]:  length 618600 bytes (604 KB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 604 KB\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Die heruntergeladenen Binärpakete sind in \n",
      "\t/var/folders/vg/vt1jjh256dn1g4sd6pknwxbs_qmnws/T//RtmpMZUxWz/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "install.packages(\"matrixStats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 244191 Columns: 2\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (2): transcript_id, gene_id\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: 2 \n",
      "R[write to console]: 3 \n",
      "R[write to console]: 4 \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: transcripts missing from tx2gene: 31380\n",
      "\n",
      "R[write to console]: summarizing abundance\n",
      "\n",
      "R[write to console]: summarizing counts\n",
      "\n",
      "R[write to console]: summarizing length\n",
      "\n",
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: 2 \n",
      "R[write to console]: 3 \n",
      "R[write to console]: 4 \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: transcripts missing from tx2gene: 31380\n",
      "\n",
      "R[write to console]: summarizing abundance\n",
      "\n",
      "R[write to console]: summarizing counts\n",
      "\n",
      "R[write to console]: summarizing length\n",
      "\n",
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: 2 \n",
      "R[write to console]: 3 \n",
      "R[write to console]: 4 \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: transcripts missing from tx2gene: 31380\n",
      "\n",
      "R[write to console]: summarizing abundance\n",
      "\n",
      "R[write to console]: summarizing counts\n",
      "\n",
      "R[write to console]: summarizing length\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: 2 \n",
      "R[write to console]: 3 \n",
      "R[write to console]: 4 \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: transcripts missing from tx2gene: 31498\n",
      "\n",
      "R[write to console]: summarizing abundance\n",
      "\n",
      "R[write to console]: summarizing counts\n",
      "\n",
      "R[write to console]: summarizing length\n",
      "\n",
      "R[write to console]: summarizing inferential replicates\n",
      "\n",
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: 2 \n",
      "R[write to console]: 3 \n",
      "R[write to console]: 4 \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: transcripts missing from tx2gene: 31380\n",
      "\n",
      "R[write to console]: summarizing abundance\n",
      "\n",
      "R[write to console]: summarizing counts\n",
      "\n",
      "R[write to console]: summarizing length\n",
      "\n",
      "R[write to console]: summarizing inferential replicates\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: 2 \n",
      "R[write to console]: 3 \n",
      "R[write to console]: 4 \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: 2 \n",
      "R[write to console]: 3 \n",
      "R[write to console]: 4 \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "library(tximport)\n",
    "library(readr)\n",
    "library(matrixStats)\n",
    "dir <- \"./data/fabry_disease\"\n",
    "tx2gene <- read_tsv(file.path(dir, \"transcript_gene_mapping_human.tsv\"))\n",
    "files <- c(\n",
    "    file.path(dir, \"SRR16504309_wt/quant.sf\"),\n",
    "    file.path(dir, \"SRR16504310_wt/quant.sf\"),\n",
    "    file.path(dir, \"SRR16504311_ko/quant.sf\"),\n",
    "    file.path(dir, \"SRR16504312_ko/quant.sf\")\n",
    ")\n",
    "countsFromAbundanceOptions <- c(\"no\", \"scaledTPM\", \"lengthScaledTPM\")\n",
    "for (idx in seq_along(countsFromAbundanceOptions)) {\n",
    "    txi <- tximport(\n",
    "        files,\n",
    "        type = \"salmon\",\n",
    "        tx2gene = tx2gene,\n",
    "        countsFromAbundance = countsFromAbundanceOptions[idx],\n",
    "        dropInfReps = TRUE,\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport.csv\")\n",
    "    if (!is.null(countsFromAbundanceOptions[idx])) {\n",
    "        writePath <- gsub(\".csv\", paste0(\"_\", countsFromAbundanceOptions[idx], \".csv\"), writePath)\n",
    "    }\n",
    "    write.csv(txi$counts, writePath)\n",
    "}\n",
    "dataTypeOptions <- c(\"kallisto\", \"salmon\")\n",
    "for (idx in seq_along(dataTypeOptions)) {\n",
    "\n",
    "    if (dataTypeOptions[idx] == \"kallisto\") {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504310_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504311_ko/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504312_ko/abundance.h5\")\n",
    "        )\n",
    "    } else {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504310_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504311_ko/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504312_ko/quant.sf\")\n",
    "        )\n",
    "    }\n",
    "\n",
    "    txi <- tximport(\n",
    "        files,\n",
    "        type = dataTypeOptions[idx],\n",
    "        tx2gene = tx2gene,\n",
    "        countsFromAbundance = \"no\",\n",
    "        dropInfReps = FALSE,\n",
    "        infRepStat = rowMedians,\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport_bootstrap.csv\")\n",
    "    writePath <- gsub(\".csv\", paste0(\"_\", dataTypeOptions[idx], \".csv\"), writePath)\n",
    "    write.csv(txi$counts, writePath)\n",
    "}\n",
    "for (idx in seq_along(dataTypeOptions)) {\n",
    "\n",
    "    if (dataTypeOptions[idx] == \"kallisto\") {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504310_wt/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504311_ko/abundance.h5\"),\n",
    "            file.path(dir, \"SRR16504312_ko/abundance.h5\")\n",
    "        )\n",
    "    } else {\n",
    "        files <- c(\n",
    "            file.path(dir, \"SRR16504309_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504310_wt/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504311_ko/quant.sf\"),\n",
    "            file.path(dir, \"SRR16504312_ko/quant.sf\")\n",
    "        )\n",
    "    }\n",
    "\n",
    "    txi <- tximport(\n",
    "        files,\n",
    "        type = dataTypeOptions[idx],\n",
    "        tx2gene = tx2gene,\n",
    "        countsFromAbundance = \"no\",\n",
    "        txOut = TRUE,\n",
    "        dropInfReps = FALSE,\n",
    "        infRepStat = rowMedians,\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport_bootstrap_transcripts.csv\")\n",
    "    writePath <- gsub(\".csv\", paste0(\"_\", dataTypeOptions[idx], \".csv\"), writePath)\n",
    "    write.csv(txi$counts, writePath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 15:57:10,820: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.01it/s]\n",
      "2024-09-11 15:57:12,265: Converting transcript-level expression to gene-level expression.\n",
      "2024-09-11 15:57:12,701: Not all transcripts are present in the mapping. 31380 out of 253181 missing. Removing the missing transcripts.\n",
      "2024-09-11 15:57:12,991: Matching gene_ids.\n",
      "2024-09-11 15:57:13,168: Creating gene abundance.\n",
      "2024-09-11 15:57:13,470: Creating gene counts.\n",
      "2024-09-11 15:57:13,471: Creating lengths.\n",
      "2024-09-11 15:57:13,595: Replacing missing lengths.\n",
      "2024-09-11 15:57:13,680: Creating gene expression dataset.\n",
      "2024-09-11 15:57:13,710: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_no.csv.\n",
      "2024-09-11 15:57:13,784: Finished the import in 2.96 seconds.\n",
      "2024-09-11 15:57:14,837: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  2.99it/s]\n",
      "2024-09-11 15:57:16,319: Converting transcript-level expression to gene-level expression.\n",
      "2024-09-11 15:57:16,741: Not all transcripts are present in the mapping. 31380 out of 253181 missing. Removing the missing transcripts.\n",
      "2024-09-11 15:57:17,020: Matching gene_ids.\n",
      "2024-09-11 15:57:17,213: Creating gene abundance.\n",
      "2024-09-11 15:57:17,549: Creating gene counts.\n",
      "2024-09-11 15:57:17,550: Creating lengths.\n",
      "2024-09-11 15:57:17,672: Replacing missing lengths.\n",
      "2024-09-11 15:57:17,758: Recreating gene counts from abundances.\n",
      "2024-09-11 15:57:17,758: Setting the counts to scaled TPM.\n",
      "2024-09-11 15:57:17,759: Creating gene expression dataset.\n",
      "2024-09-11 15:57:17,791: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_scaledTPM.csv.\n",
      "2024-09-11 15:57:17,885: Finished the import in 3.05 seconds.\n",
      "2024-09-11 15:57:18,932: Starting the import.\n",
      "Reading quantification files: 4it [00:01,  3.19it/s]\n",
      "2024-09-11 15:57:20,341: Converting transcript-level expression to gene-level expression.\n",
      "2024-09-11 15:57:20,736: Not all transcripts are present in the mapping. 31380 out of 253181 missing. Removing the missing transcripts.\n",
      "2024-09-11 15:57:21,004: Matching gene_ids.\n",
      "2024-09-11 15:57:21,173: Creating gene abundance.\n",
      "2024-09-11 15:57:21,441: Creating gene counts.\n",
      "2024-09-11 15:57:21,442: Creating lengths.\n",
      "2024-09-11 15:57:21,559: Replacing missing lengths.\n",
      "2024-09-11 15:57:21,636: Recreating gene counts from abundances.\n",
      "2024-09-11 15:57:21,636: Setting counts to length scaled TPM.\n",
      "2024-09-11 15:57:21,639: Creating gene expression dataset.\n",
      "2024-09-11 15:57:21,665: Saving the gene-level expression to: data/fabry_disease/counts_pytximport_lengthScaledTPM.csv.\n",
      "2024-09-11 15:57:21,757: Finished the import in 2.83 seconds.\n"
     ]
    }
   ],
   "source": [
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt/quant.sf -i ./data/fabry_disease/SRR16504310_wt/quant.sf -i ./data/fabry_disease/SRR16504311_ko/quant.sf -i ./data/fabry_disease/SRR16504312_ko/quant.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.tsv -ow -o ./data/fabry_disease/counts_pytximport_no.csv\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt/quant.sf -i ./data/fabry_disease/SRR16504310_wt/quant.sf -i ./data/fabry_disease/SRR16504311_ko/quant.sf -i ./data/fabry_disease/SRR16504312_ko/quant.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.tsv -ow -o ./data/fabry_disease/counts_pytximport_scaledTPM.csv -c scaled_tpm\n",
    "!pytximport -i ./data/fabry_disease/SRR16504309_wt/quant.sf -i ./data/fabry_disease/SRR16504310_wt/quant.sf -i ./data/fabry_disease/SRR16504311_ko/quant.sf -i ./data/fabry_disease/SRR16504312_ko/quant.sf -t salmon -m ./data/fabry_disease/transcript_gene_mapping_human.tsv -ow -o ./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv -c length_scaled_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "counts_tximport_no = pd.read_csv(\"./data/fabry_disease/counts_tximport_no.csv\")\n",
    "counts_tximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_scaledTPM.csv\")\n",
    "counts_tximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_tximport_lengthScaledTPM.csv\")\n",
    "\n",
    "counts_pytximport_no = pd.read_csv(\"./data/fabry_disease/counts_pytximport_no.csv\")\n",
    "counts_pytximport_scaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_scaledTPM.csv\")\n",
    "counts_pytximport_lengthScaledTPM = pd.read_csv(\"./data/fabry_disease/counts_pytximport_lengthScaledTPM.csv\")\n",
    "counts_pytximport_no.columns = counts_tximport_no.columns\n",
    "counts_pytximport_scaledTPM.columns = counts_tximport_scaledTPM.columns\n",
    "counts_pytximport_lengthScaledTPM.columns = counts_tximport_lengthScaledTPM.columns\n",
    "\n",
    "pd.testing.assert_frame_equal(counts_tximport_no, counts_pytximport_no)\n",
    "pd.testing.assert_frame_equal(counts_tximport_scaledTPM, counts_pytximport_scaledTPM)\n",
    "pd.testing.assert_frame_equal(counts_tximport_lengthScaledTPM, counts_pytximport_lengthScaledTPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare outputs for transcript-level summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 244191 Columns: 2\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (2): transcript_id, gene_id\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "dir <- \"./data/salmon\"\n",
    "files_protein_coding <- c(\n",
    "  file.path(dir, \"quant.sf\")\n",
    ")\n",
    "tx2gene <- read_tsv(file.path(\"./data/fabry_disease\", \"transcript_gene_mapping_human.tsv\"))\n",
    "countsFromAbundanceOptions <- c(\"scaledTPM\", \"dtuScaledTPM\")\n",
    "for (idx in seq_along(countsFromAbundanceOptions)) {\n",
    "    txi <- tximport(\n",
    "        files_protein_coding,\n",
    "        type = \"salmon\",\n",
    "        tx2gene = tx2gene,\n",
    "        txOut = TRUE,\n",
    "        countsFromAbundance = countsFromAbundanceOptions[idx],\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport.csv\")\n",
    "    if (!is.null(countsFromAbundanceOptions[idx])) {\n",
    "        writePath <- gsub(\".csv\", paste0(\"_\", countsFromAbundanceOptions[idx], \".csv\"), writePath)\n",
    "    }\n",
    "    write.csv(txi$counts, writePath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 15:57:23,917: Starting the import.\n",
      "Reading quantification files: 1it [00:00, 295.69it/s]\n",
      "2024-09-11 15:57:24,266: Recreating transcript counts from abundances.\n",
      "2024-09-11 15:57:24,266: Setting counts to length scaled TPM.\n",
      "2024-09-11 15:57:24,267: Saving the gene-level expression to: data/salmon/counts_pytximport_dtuScaledTPM.csv.\n",
      "2024-09-11 15:57:24,270: Finished the import in 0.35 seconds.\n"
     ]
    }
   ],
   "source": [
    "!pytximport -i ./data/salmon/quant.sf -m ./data/fabry_disease/transcript_gene_mapping_human.tsv  -ow  -o ./data/salmon/counts_pytximport_dtuScaledTPM.csv -t salmon -tx -c dtu_scaled_tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_tximport_dtuScaledTPM = pd.read_csv(\"./data/salmon/counts_tximport_dtuScaledTPM.csv\", index_col=0).sort_index()\n",
    "counts_pytximport_dtuScaledTPM = pd.read_csv(\n",
    "    \"./data/salmon/counts_pytximport_dtuScaledTPM.csv\", index_col=0\n",
    ").sort_index()\n",
    "# cut the transcript version from the index\n",
    "counts_tximport_dtuScaledTPM.index = counts_tximport_dtuScaledTPM.index.str.split(\".\").str[0]\n",
    "counts_pytximport_dtuScaledTPM.columns = counts_tximport_dtuScaledTPM.columns\n",
    "\n",
    "pd.testing.assert_frame_equal(counts_tximport_dtuScaledTPM, counts_pytximport_dtuScaledTPM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare outputs for RSEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 244191 Columns: 2\n",
      "── Column specification ────────────────────────────────────────────────────────\n",
      "Delimiter: \"\\t\"\n",
      "chr (2): transcript_id, gene_id\n",
      "\n",
      "ℹ Use `spec()` to retrieve the full column specification for this data.\n",
      "ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: reading in files with read_tsv\n",
      "\n",
      "R[write to console]: 1 \n",
      "R[write to console]: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "dir <- \"./data/rsem\"\n",
    "files_protein_coding <- c(\n",
    "  file.path(dir, \"test.genes.results.gz\")\n",
    ")\n",
    "tx2gene <- read_tsv(file.path(\"./data/fabry_disease\", \"transcript_gene_mapping_human.tsv\"))\n",
    "countsFromAbundanceOptions <- c(\"no\")\n",
    "for (idx in seq_along(countsFromAbundanceOptions)) {\n",
    "    txi <- tximport(\n",
    "        files_protein_coding,\n",
    "        type = \"rsem\",\n",
    "        tx2gene = tx2gene,\n",
    "        txIn = FALSE,\n",
    "        countsFromAbundance = countsFromAbundanceOptions[idx],\n",
    "        ignoreTxVersion = TRUE,\n",
    "        ignoreAfterBar = TRUE\n",
    "    )\n",
    "    writePath <- file.path(dir, \"counts_tximport.csv\")\n",
    "    if (!is.null(countsFromAbundanceOptions[idx])) {\n",
    "        writePath <- gsub(\".csv\", paste0(\"_\", countsFromAbundanceOptions[idx], \".csv\"), writePath)\n",
    "    }\n",
    "    write.csv(txi$counts, writePath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
